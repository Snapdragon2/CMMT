{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start. 2019-10-09 18:45:42.458587\n",
      "done. 2019-10-09 18:45:42.467627\n"
     ]
    }
   ],
   "source": [
    "#clean text and create stoplist\n",
    "import jieba\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora, models, similarities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "print(\"start.\",datetime.datetime.now())\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \") #newline\n",
    "    text = re.sub(r\"-\", \" \", text) #\"-\"\n",
    "    text = re.sub(r\"\\d+/\\d+/\\d+\", \"\", text) #timestamp\n",
    "    text = re.sub(r\"[\\w]+@[\\.\\w]+\", \"\", text) #ML\n",
    "    text = re.sub(r\"<.*?>\", \"\", text) #pic\n",
    "    text = re.sub(r\"/[a-zA-Z]*[:\\//\\]*[A-Za-z0-9\\-_]+\\.+[A-Za-z0-9\\.\\/%&=\\?\\-_]+/i\", \"\", text)\n",
    "    pure_text = \"\"\n",
    "    for letter in text:\n",
    "        if letter.isalpha() or letter == \" \":\n",
    "            pure_text+=letter\n",
    "    text = \" \".join(word for word in pure_text.split() if len(word) > 1)\n",
    "    return text\n",
    "\n",
    "stoplist = pd.read_csv(\"/Users/CM/desktop/LDA2/stopzh.csv\")[\"BodyText\"].values\n",
    "print(\"done.\",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start. 2019-10-09 18:45:43.883433\n",
      "done. 2019-10-09 18:46:43.041481\n"
     ]
    }
   ],
   "source": [
    "#csv→clean_text→clean_stoppoint→into_corpora\n",
    "# Gensim\n",
    "print(\"start.\",datetime.datetime.now())\n",
    "\n",
    "df = pd.read_csv(\"/Users/CM/Desktop/LDA2/ldazhtxt.csv\")\n",
    "df = df[[\"BodyText\"]].dropna()\n",
    "\n",
    "docs = df[\"BodyText\"]\n",
    "docs = docs.apply(lambda s: clean_text(s))\n",
    "\n",
    "doclist = docs.values\n",
    "texts1 = []\n",
    "\n",
    "for i in doclist:\n",
    "#    print(i)\n",
    "    doclist2 = jieba.cut(i, cut_all=False,HMM=True)\n",
    "    temp = \" \"\n",
    "    for word in doclist2:\n",
    "        if word not in stoplist:\n",
    "            if word != '\\t':\n",
    "                if word != \" \":\n",
    "                    temp += word\n",
    "                    temp += \" \"\n",
    "#    print(temp)\n",
    "#    print(temp.strip().split(\" \"))\n",
    "    texts1.append(temp.strip().split(\" \"))\n",
    "\n",
    "#texts1 = [[word for word in doc.split() if word not in stoplist] for doc in doclist1]\n",
    "#texts1 = [[word for word in doc if word not in stoplist] for doc in doclist1]\n",
    "\n",
    "#for i in range(20):\n",
    "#    print(texts1[i])\n",
    "\n",
    "texts = [doc for doc in texts1 if doc != []]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "print(\"done.\",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start. 2019-10-09 19:00:35.693924\n",
      "done. 2019-10-09 19:06:14.010189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.011*\"文库\" + 0.008*\"lncRNA\" + 0.008*\"激活\" + 0.008*\"转录\" + 0.007*\"表达\" + 0.007*\"sgRNA\" + 0.007*\"CRISPRCas\" + 0.006*\"凋亡\" + 0.006*\"应用\" + 0.006*\"MS\" + 0.005*\"筛选\" + 0.005*\"公司\" + 0.004*\"载体\" + 0.004*\"每个\" + 0.004*\"机制\" + 0.004*\"起始\" + 0.004*\"生物\" + 0.004*\"A\" + 0.004*\"CART\" + 0.004*\"B\"'),\n",
       " (1,\n",
       "  '0.006*\"公司\" + 0.005*\"检测\" + 0.004*\"测试\" + 0.004*\"治疗\" + 0.003*\"疾病\" + 0.003*\"患者\" + 0.003*\"启动子\" + 0.003*\"医生\" + 0.003*\"诊断\" + 0.003*\"天花\" + 0.003*\"现在\" + 0.002*\"詹纳\" + 0.002*\"美国\" + 0.002*\"病毒\" + 0.002*\"疗法\" + 0.002*\"癌症\" + 0.002*\"预测\" + 0.002*\"中国\" + 0.002*\"问题\" + 0.002*\"提供\"'),\n",
       " (2,\n",
       "  '0.020*\"规模\" + 0.015*\"工具\" + 0.012*\"全球\" + 0.010*\"万元\" + 0.009*\"中国\" + 0.008*\"市场\" + 0.006*\"类型\" + 0.006*\"表\" + 0.006*\"发展\" + 0.006*\"不同\" + 0.006*\"分析\" + 0.005*\"介绍\" + 0.005*\"企业\" + 0.005*\"公司\" + 0.005*\"市场份额\" + 0.005*\"预测\" + 0.005*\"增长率\" + 0.004*\"未来\" + 0.004*\"毛利率\" + 0.004*\"应用领域\"'),\n",
       " (3,\n",
       "  '0.011*\"CCR\" + 0.011*\"脱靶\" + 0.009*\"HIV\" + 0.009*\"突变\" + 0.008*\"治疗\" + 0.008*\"病毒\" + 0.007*\"小鼠\" + 0.006*\"基因组\" + 0.006*\"干细胞\" + 0.005*\"团队\" + 0.005*\"免疫\" + 0.005*\"艾滋病\" + 0.005*\"方法\" + 0.004*\"论文\" + 0.004*\"Cas\" + 0.004*\"移植\" + 0.004*\"碱基\" + 0.004*\"发表\" + 0.004*\"发现\" + 0.004*\"患者\"'),\n",
       " (4,\n",
       "  '0.005*\"Csm\" + 0.005*\"疾病\" + 0.004*\"专利\" + 0.004*\"猪\" + 0.004*\"亨廷顿\" + 0.003*\"复合物\" + 0.003*\"生物\" + 0.003*\"美国\" + 0.003*\"模型\" + 0.003*\"神经\" + 0.003*\"III\" + 0.003*\"重要\" + 0.003*\"退行性\" + 0.002*\"论文\" + 0.002*\"科学家\" + 0.002*\"克隆\" + 0.002*\"申请\" + 0.002*\"工作\" + 0.002*\"教授\" + 0.002*\"团队\"'),\n",
       " (5,\n",
       "  '0.015*\"贺建奎\" + 0.008*\"中国\" + 0.005*\"科学家\" + 0.005*\"猴子\" + 0.005*\"婴儿\" + 0.004*\"美国\" + 0.004*\"斯坦福大学\" + 0.004*\"人员\" + 0.004*\"动物\" + 0.003*\"调查\" + 0.003*\"深圳\" + 0.003*\"事件\" + 0.003*\"表示\" + 0.003*\"变异\" + 0.003*\"伦理\" + 0.003*\"大学\" + 0.002*\"蓝藻\" + 0.002*\"基因组\" + 0.002*\"奎克\" + 0.002*\"灵长类\"'),\n",
       " (6,\n",
       "  '0.011*\"治疗\" + 0.007*\"患者\" + 0.007*\"疗法\" + 0.006*\"基因治疗\" + 0.005*\"临床试验\" + 0.003*\"CAR\" + 0.003*\"载体\" + 0.003*\"试验\" + 0.003*\"AAV\" + 0.003*\"疾病\" + 0.003*\"番茄\" + 0.003*\"美国\" + 0.003*\"临床\" + 0.003*\"表达\" + 0.003*\"辣椒素\" + 0.003*\"TCR\" + 0.003*\"病毒\" + 0.003*\"PD\" + 0.002*\"方法\" + 0.002*\"纤维化\"'),\n",
       " (7,\n",
       "  '0.011*\"问题\" + 0.008*\"实验\" + 0.008*\"婴儿\" + 0.007*\"伦理\" + 0.007*\"贺建奎\" + 0.005*\"转基因\" + 0.005*\"孩子\" + 0.005*\"现在\" + 0.005*\"生物\" + 0.005*\"科学家\" + 0.004*\"社会\" + 0.004*\"中国\" + 0.004*\"事件\" + 0.004*\"未来\" + 0.003*\"影响\" + 0.003*\"世界\" + 0.003*\"风险\" + 0.003*\"改造\" + 0.003*\"国家\" + 0.003*\"艾滋病\"'),\n",
       " (8,\n",
       "  '0.020*\"Cas\" + 0.013*\"序列\" + 0.011*\"蛋白\" + 0.008*\"基因组\" + 0.007*\"酶\" + 0.006*\"发现\" + 0.006*\"CRISPRCas\" + 0.006*\"表达\" + 0.005*\"位点\" + 0.005*\"细菌\" + 0.005*\"切割\" + 0.005*\"修复\" + 0.005*\"识别\" + 0.005*\"应用\" + 0.004*\"突变\" + 0.004*\"结合\" + 0.004*\"小鼠\" + 0.004*\"方法\" + 0.004*\"sgRNA\" + 0.004*\"筛选\"'),\n",
       " (9,\n",
       "  '0.012*\"遗传\" + 0.010*\"资源\" + 0.007*\"检测\" + 0.006*\"国家\" + 0.005*\"我国\" + 0.004*\"条例\" + 0.004*\"SHERLOCK\" + 0.004*\"法律\" + 0.004*\"采集\" + 0.003*\"规定\" + 0.003*\"保藏\" + 0.003*\"保护\" + 0.003*\"诊断\" + 0.003*\"提供\" + 0.003*\"要求\" + 0.002*\"组织\" + 0.002*\"图片\" + 0.002*\"活动\" + 0.002*\"内容\" + 0.002*\"万元\"')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "print(\"start.\",datetime.datetime.now())\n",
    "\n",
    "num_topics = 10\n",
    "chunksize = 6000\n",
    "passes = 400\n",
    "iterations = 400\n",
    "eval_every = None\n",
    "\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus = corpus, id2word = dictionary,chunksize=chunksize, \\\n",
    "                                      alpha='auto', eta='auto',eval_every=eval_every, \\\n",
    "                                      iterations=iterations,passes = passes,num_topics = num_topics)\n",
    "\n",
    "print(\"done.\",datetime.datetime.now())\n",
    "lda.print_topics(num_topics = num_topics, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -6.780045484780302\n"
     ]
    }
   ],
   "source": [
    "print(\"Perplexity: \", lda.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基因 编辑 技术 细胞 基因组 人类 序列 蛋白 小鼠 系统 位点 病毒 科学家 婴儿 胚胎 碱基 生物 疾病 团队 问题 工具 转基因 艾滋病 靶向 方法 细菌 干细胞 基因治疗 利用 外源\n"
     ]
    }
   ],
   "source": [
    "from jieba import analyse\n",
    "#spa = []\n",
    "#for i in doclist:\n",
    "#    spa.append(i)\n",
    "    \n",
    "#analyse.extract_tags(spa, topK = 20, withWeight = False, allowPOS=())\n",
    "with open(\"/Users/CM/Desktop/LDA2/ldazhtxt.csv\") as f:\n",
    "    lines = f.read()\n",
    "    words = analyse.extract_tags(lines, topK = 30, allowPOS=('n'))\n",
    "    print(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
