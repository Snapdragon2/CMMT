{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      QClink\n",
      "0      https://zhuanlan.zhihu.com/p/41999290\n",
      "1   https://www.zhihu.com/question/271554836\n",
      "2   https://www.zhihu.com/question/271566733\n",
      "3   https://www.zhihu.com/question/274072414\n",
      "4      https://zhuanlan.zhihu.com/p/48541437\n",
      "5      https://zhuanlan.zhihu.com/p/55804262\n",
      "6   https://www.zhihu.com/question/274037224\n",
      "7   https://www.zhihu.com/question/265622320\n",
      "8   https://www.zhihu.com/question/275844528\n",
      "9   https://www.zhihu.com/question/274059149\n",
      "10  https://www.zhihu.com/question/272369008\n",
      "11  https://www.zhihu.com/question/267691626\n",
      "12  https://www.zhihu.com/question/266420817\n",
      "13  https://www.zhihu.com/question/270493569\n"
     ]
    }
   ],
   "source": [
    "#0916:all question and column links from topic \"基因驱动\" \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from pyquery import PyQuery as pq\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import csv\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "#------------------------------------------------------------1st stage,collect all question/column links\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.zhihu.com/topic/20139164/hot\"\n",
    "    \n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#scroll to the topic bottom\n",
    "for i in range(6):\n",
    "    js = \"var q = document.documentElement.scrollTop=\"+str(i*1000)\n",
    "    driver.execute_script(js)\n",
    "    time.sleep(0.8)\n",
    "time.sleep(2)\n",
    "\n",
    "listql = []\n",
    "soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "for b in soup.findAll(\"meta\",attrs = {\"itemprop\":\"url\"}):\n",
    "    c = b[\"content\"]\n",
    "    if \"question\" in c and \"answer\" not in c and c not in listql:\n",
    "        listql.append(c) \n",
    "    if \"zhuanlan\" in c and c not in listql:\n",
    "        listql.append(c) \n",
    "\n",
    "#url = \"https://www.zhihu.com/topic/20741067/top-answers\"\n",
    "driver.find_element_by_link_text(\"精华\").click()\n",
    "time.sleep(2)\n",
    "driver.implicitly_wait(10)\n",
    "time.sleep(2)\n",
    "\n",
    "#scroll to the topic bottom\n",
    "for i in range(4):\n",
    "    js = \"var q = document.documentElement.scrollTop=\"+str(i*1000)\n",
    "    driver.execute_script(js)\n",
    "    time.sleep(0.8)\n",
    "time.sleep(2)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "for b in soup.findAll(\"meta\",attrs = {\"itemprop\":\"url\"}):\n",
    "    c = b[\"content\"]\n",
    "    if \"question\" in c and \"answer\" not in c and c not in listql:\n",
    "        listql.append(c) \n",
    "    if \"zhuanlan\" in c and c not in listql:\n",
    "        listql.append(c) \n",
    "\n",
    "        \n",
    "#url = \"https://www.zhihu.com/topic/20741067/unanswered\"\n",
    "driver.find_element_by_link_text(\"等待回答\").click()\n",
    "driver.implicitly_wait(10)\n",
    "time.sleep(2)\n",
    "\n",
    "#scroll to the topic bottom\n",
    "for i in range(8):\n",
    "    js = \"var q = document.documentElement.scrollTop=\"+str(i*1000)\n",
    "    driver.execute_script(js)\n",
    "    time.sleep(0.8)\n",
    "time.sleep(2)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "        \n",
    "for b in soup.findAll(\"a\"):\n",
    "    c = b[\"href\"]\n",
    "    d = \"https://www.zhihu.com\" + c\n",
    "    if \"question\" in c and len(c) == 19 and \"topic\" not in c and \"write_answer\" not in c and d not in listql:\n",
    "        listql.append(d)\n",
    "\n",
    "\n",
    "listql = [re.sub(\"^https:/+\",\"https://\",i) for i in listql]\n",
    "\n",
    "save = \"/Users/CM/desktop/ScrapeZQ2/QClink/ql-jyqd.csv\"\n",
    "df = pd.DataFrame(listql,columns = [\"QClink\"])\n",
    "df1 = df.to_csv(save, index = False)\n",
    "print(pd.read_csv(save))\n",
    "#------------------------------------------------------------2nd stage,collect question/column details\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zhihu.com/question/274072414\n",
      "https://www.zhihu.com/question/274037224\n",
      "https://www.zhihu.com/question/275844528\n",
      "https://www.zhihu.com/question/267691626\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "#0916:question and column detail from topic \"基因驱动\" \n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#scan the QR code manually to login\n",
    "driver.get(\"https://www.zhihu.com/\")\n",
    "time.sleep(12)\n",
    "\n",
    "with open(\"/Users/CM/desktop/ScrapeZQ2/qca-jyqd.csv\",\"w\",encoding = \"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"column\",\"title\",\"flwr\",\"v\",\"authlink\",\"upno\",\"cmtno\",\"andate\",\"textlen\",\"imgno\",\"antext\"])\n",
    "    df1 = pd.read_csv(\"/Users/CM/desktop/ScrapeZQ2/QClink/ql-jyqd.csv\")[\"QClink\"].values\n",
    "\n",
    "    for qcl in df1:\n",
    "        driver.get(qcl)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "    \n",
    "        try:            \n",
    "            if \"question\" in qcl:\n",
    "                #get question info\n",
    "                column = \"0\"\n",
    "                qtitle = soup.find(\"h1\", class_=\"QuestionHeader-title\").get_text()+soup.find(\"div\", class_=\"QuestionHeader-detail\").get_text()\n",
    "                qflwr = soup.findAll(\"strong\", class_=\"NumberBoard-itemValue\")[0].get_text()\n",
    "                qv = soup.findAll(\"strong\", class_=\"NumberBoard-itemValue\")[1].get_text()                \n",
    "\n",
    "                if len(soup.findAll(\"h4\", class_=\"List-headerText\")) > 0:\n",
    "                    #unfold qtext\n",
    "                    time.sleep(1)\n",
    "                    try:\n",
    "                        driver.find_element_by_xpath(\"//div[@class='QuestionRichText QuestionRichText--expandable QuestionRichText--collapsed']\").click()\n",
    "                        time.sleep(2)\n",
    "                    except:\n",
    "                        time.sleep(2)\n",
    "                    \n",
    "                    #scroll to the bottom\n",
    "                    xhd = soup.findAll(\"button\", class_=\"Button QuestionAnswers-answerButton Button--blue Button--spread\")\n",
    "                    an = soup.findAll(\"span\", class_=\"RichText ztext CopyrightRichText-richText\")\n",
    "                    if len(an) > 0:\n",
    "                        n = 1\n",
    "                        while len(xhd) == 0:\n",
    "                            js = \"var q = document.documentElement.scrollTop=\"+str(n*1000)\n",
    "                            driver.execute_script(js)\n",
    "                            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "                            xhd = soup.findAll(\"button\", class_=\"Button QuestionAnswers-answerButton Button--blue Button--spread\")\n",
    "                            n+=1\n",
    "                            time.sleep(0.6)\n",
    "                    \n",
    "                    #get all answer info\n",
    "                    ans = soup.findAll(\"div\", class_=\"List-item\")\n",
    "                    for ai in ans:\n",
    "                        #authname = ai.find(\"span\", class_=\"UserLink AuthorInfo-name\").get_text()\n",
    "                        try:\n",
    "                            authlink = re.sub(\"^//\",\"https://\",ai.find(\"a\", class_=\"UserLink-link\")[\"href\"])\n",
    "                        except:\n",
    "                            authlink = \"AnonymousUser\"\n",
    "                        upno = ai.find(\"button\", class_=\"Button VoteButton VoteButton--up\").get_text()\n",
    "                        #upno = [i.get_text() for i in ai.findAll(\"button\", class_=\"Button VoteButton VoteButton--up\")]\n",
    "                        cmtno = ai.find(\"button\", class_=\"Button ContentItem-action Button--plain Button--withIcon Button--withLabel\").get_text()\n",
    "                        #cmtno = soup.find(\"button\", class_=\"Button ContentItem-action Button--plain Button--withIcon Button--withLabel\").get_text()                \n",
    "                        andate = ai.find(\"div\", class_=\"ContentItem-time\").get_text()\n",
    "                        imgno = str(len(ai.findAll(\"figure\")))+\"个图片\"\n",
    "                        antext = ai.find(\"span\", class_=\"RichText ztext CopyrightRichText-richText\").get_text()\n",
    "                        textlen = str(len(antext))+\"个文字\"\n",
    "                        writer.writerow([column,qtitle,qflwr,qv,authlink,upno,cmtno,andate,textlen,imgno,antext])\n",
    "                else:\n",
    "                    authlink = \"AnonymousUser\"\n",
    "                    writer.writerow([column,qtitle,qflwr,qv,authlink])                   \n",
    "                    \n",
    "            elif \"zhuanlan\" in qcl:\n",
    "                soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "                 \n",
    "                column = \"1\"\n",
    "                coltitle = soup.find(\"h1\", class_=\"Post-Title\").get_text()\n",
    "                #authname = soup.find(\"a\", class_=\"UserLink-link\").get_text()\n",
    "                colflwr = \"NoColflwr\"\n",
    "                colv = \"NoColv\"\n",
    "                #authlink = soup.find(\"a\", class_=\"UserLink-link\")[\"href\"]\n",
    "                authlink = re.sub(\"^//\",\"https://\",soup.find(\"a\", class_=\"UserLink-link\")[\"href\"])\n",
    "                #upno = soup.find(\"button\", class_=\"Button VoteButton VoteButton--up\").get_text()\n",
    "                upno = soup.find(\"button\", class_=\"Button VoteButton VoteButton--up\").get_text()\n",
    "                #cmtno = soup.find(\"button\", class_=\"Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel\").get_text()\n",
    "                cmtno = soup.find(\"button\", class_=\"Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel\").get_text()\n",
    "                coldate = soup.find(\"div\", class_=\"ContentItem-time\").get_text()\n",
    "                imgno = str(len(soup.findAll(\"figure\")))+\"个图片\"\n",
    "                coltext = soup.find(\"div\", class_=\"Post-RichTextContainer\").get_text()\n",
    "                textlen = str(len(coltext))+\"个文字\"\n",
    "                writer.writerow([column,coltitle,colflwr,colv,authlink,upno,cmtno,coldate,textlen,imgno,coltext])\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except:\n",
    "            print(qcl) \n",
    "\n",
    "print(\"done.\")\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zhihu.com/people/wu-gan-lin-85\n",
      "https://www.zhihu.com/people/long-gong-yu-41\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "#0916:answerers detail in topic \"基因驱动\" \n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#scan the QR code manually to login\n",
    "driver.get(\"https://www.zhihu.com/\")\n",
    "time.sleep(10)\n",
    "\n",
    "with open(\"/Users/CM/desktop/ScrapeZQ2/ai-jyqd.csv\",\"w\",encoding = \"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"authlink\",\"authname\",\"verified\",\"authflwr\",\"authupno\"])\n",
    "    df2 = pd.read_csv(\"/Users/CM/desktop/ScrapeZQ2/qca-jyqd.csv\")[\"authlink\"].values\n",
    "    for al in df2:\n",
    "        if al != \"AnonymousUser\":\n",
    "            driver.get(al)\n",
    "            driver.implicitly_wait(8)\n",
    "            soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "            \n",
    "            try:\n",
    "                if len(soup.findAll(\"div\", class_=\"ProfileMainPrivacy-mainContentWrapper\")) == 0:\n",
    "                    authlink = al\n",
    "                    authname = soup.find(\"span\",class_=\"ProfileHeader-name\").get_text()\n",
    "                    if soup.find(\"div\", class_=\"Card-headerText\").get_text() == \"个人成就\":\n",
    "                        verified = \"0\"\n",
    "                    if soup.find(\"div\", class_=\"Card-headerText\").get_text() == \"认证与成就\":\n",
    "                        verified = \"1\"\n",
    "                    authflwr = soup.findAll(\"strong\", class_=\"NumberBoard-itemValue\")[1].get_text()\n",
    "                    for i in soup.findAll(\"div\", class_=\"IconGraf\"):\n",
    "                        if \"赞同\" in i.get_text():\n",
    "                            authupno = i.get_text()\n",
    "                    writer.writerow([authlink,authname,verified,authflwr,authupno])\n",
    "                    time.sleep(1)\n",
    "            except:\n",
    "                print(al)\n",
    "                #fill up manually\n",
    "print(\"done.\")\n",
    "            \n",
    "time.sleep(1)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"随着科学的不断进步，一切问题终将得到解决，也许世界本就不是人类所认知的那样，不过那又怎样呢，在人类现有的认知范围内，世界不是远转的很正常吧。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
